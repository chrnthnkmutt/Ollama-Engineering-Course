# Topic 1. LLM API Basics

**The repository template is under construction, with new materials appearing regularly.**

## Contents

* **1.1. Intro to LLM APIs**

  Experiment with text-to-image and image-to-text generation, send API requests, and analyze responses using OpenAI API and Ollama, which provides open-source models like Llama, Mistral, DeepSeek, and Qwen. 
  This section will ensure you can make API calls, handle responses, and integrate LLMs into applications.

* 1.2. Tokenization (will be available later)

  For LLMs, text is composed of tokens, which can be words, subwords, individual characters, or even byte sequences.
  In this chapter, you'll learn what tokens are and how tokenization affects the way LLMs process text.

* 1.3. Basic prompting strategies (will be available later)

  In this chapter, we'll share some basic practical hints for prompting LLMs.

* 1.4. What can possibly go wrong with an LLM (will be available later)

  Learn about some of the blights that plague LLM users: hallucinations, bias, mode collapsing, and jailbreaks.

* 1.5. Choosing an LLM (will be available later)

  Learn about various cosiderations that you can use to choose LLMs for your projects, including size tiers, benchmarks, reasoning capabilities, etc.

* **1.6. LLM Inference Parameters** 

  Understand token probabilities, uncertainty, and the LLM generation process. 
  Learn how inference parameters influence randomness in responses and how to balance reproducibility and creativity.

* **1.7. Creating an LLM-powered Character** 
  Build a chatbot based on a fantasy character and explore advanced features like giving it a scratchpad â€” a space for its own "thoughts."